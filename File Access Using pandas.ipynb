{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 File Access Using pandas\n",
    "File(s) needed: Applewood_2011.csv, Boston_housing_SMALL.csv, fishcatch.txt, fish_info.txt, Oysters.xlsx\n",
    "\n",
    "In earlier classes we manually read text file data using base Python functionality. Today we begin to see one of the reasons why Python is so popular: libraries. Libraries are self-contained packages of coded capabilities that can be imported into Python to extend its functionality. One of the most fundamental libraries for working with data is called pandas.\n",
    "\n",
    "pandas (always with a small \"p\") contains a set of _parsers_ that read each bit of data and determine the purpose of each bit within the context of the overall file. The key is to use the correct parser for the task at hand.\n",
    "\n",
    "Have you ever seen a data file where the first row contains column headers? Of course you have! That is way more common than just having rows of data like we had before. By using the correct parser in pandas, we can automatically read the headers. Of course, we can program that ourselves in base Python, but why would we want to? Someone else already did a good job of doing it so let's use their code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a library\n",
    "First we need to talk about using a library in our code. We use the import command at the beginning of our code to access the library's functionality. We will often use the `as` clause to create a shorthand for the library.\n",
    "\n",
    "Of course, the library has to be available to you. That means it has to be downloaded and installed. This is why we are using the Anaconda product - it comes with pandas and many other libraries already included. \n",
    "\n",
    "Learn more at http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this syntax.\n",
    "# You will see that this way makes it easier to access the functions.\n",
    "# You will also see online that this is the way most people do it.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Profit   Location Vehicle-Type  Previous\n",
      "0     21    1387   Tionesta        Sedan         0\n",
      "1     23    1754  Sheffield          SUV         1\n",
      "2     24    1817  Sheffield       Hybrid         1\n",
      "3     25    1040  Sheffield      Compact         0\n",
      "4     26    1273       Kane        Sedan         1\n",
      "5     27    1529  Sheffield        Sedan         1\n",
      "6     27    3082       Kane        Truck         0\n",
      "7     28    1951       Kane          SUV         1\n",
      "8     28    2692   Tionesta      Compact         0\n",
      "9     29    1206  Sheffield        Sedan         0\n",
      "10    29    1342       Kane        Sedan         2\n",
      "11    30     443       Kane        Sedan         3\n",
      "12    30     754      Olean        Sedan         2\n",
      "13    30    1621  Sheffield        Truck         1\n",
      "14    31     870   Tionesta        Sedan         1\n",
      "15    31    1174       Kane        Truck         0\n",
      "16    31    1412  Sheffield        Sedan         1\n",
      "17    31    1809   Tionesta        Sedan         1\n",
      "18    31    2415       Kane        Sedan         0\n",
      "19    32    1546  Sheffield        Truck         3\n",
      "20    32    2148   Tionesta          SUV         2\n",
      "21    32    2207  Sheffield      Compact         0\n",
      "22    32    2252   Tionesta          SUV         0\n",
      "23    33    1428       Kane          SUV         2\n",
      "24    33    1889      Olean          SUV         1\n",
      "25    34    1166      Olean        Sedan         1\n",
      "26    34    1320   Tionesta        Sedan         1\n",
      "27    34    2265      Olean        Sedan         0\n",
      "28    35    1323      Olean        Sedan         2\n",
      "29    35    1760       Kane        Sedan         1\n",
      "..   ...     ...        ...          ...       ...\n",
      "150   56    1957  Sheffield          SUV         1\n",
      "151   56    2240      Olean        Sedan         0\n",
      "152   56    2695       Kane        Sedan         2\n",
      "153   57    1325      Olean        Sedan         1\n",
      "154   57    2250  Sheffield        Sedan         2\n",
      "155   57    2279  Sheffield       Hybrid         1\n",
      "156   57    2626  Sheffield        Sedan         2\n",
      "157   58    1501  Sheffield       Hybrid         1\n",
      "158   58    1752       Kane        Sedan         3\n",
      "159   58    2058       Kane          SUV         1\n",
      "160   58    2370   Tionesta      Compact         0\n",
      "161   58    2637  Sheffield          SUV         1\n",
      "162   59    1426  Sheffield        Sedan         0\n",
      "163   59    2944      Olean          SUV         2\n",
      "164   60    2147      Olean        Sedan         2\n",
      "165   61    1973       Kane          SUV         3\n",
      "166   61    2502      Olean        Sedan         0\n",
      "167   62     783  Sheffield       Hybrid         1\n",
      "168   62    1538      Olean        Truck         1\n",
      "169   63    2339      Olean      Compact         1\n",
      "170   64    2700       Kane        Truck         0\n",
      "171   65    2222       Kane        Truck         1\n",
      "172   65    2597  Sheffield        Truck         0\n",
      "173   65    2742   Tionesta          SUV         2\n",
      "174   68    1837  Sheffield        Sedan         1\n",
      "175   69    2842       Kane          SUV         0\n",
      "176   70    2434      Olean        Sedan         4\n",
      "177   72    1640      Olean        Sedan         1\n",
      "178   72    1821   Tionesta          SUV         1\n",
      "179   73    2487      Olean      Compact         4\n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# The data has to be stored somewhere when it is read. That means we need\n",
    "# a variable name on the left side of an assignment operator.\n",
    "applewood_table = pd.io.parsers.read_csv(\"Applewood_2011.csv\")\n",
    "print(applewood_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, let's talk about the specific parts of the above reading statement and what they do. Remember that we can use the autocomplete feature or ? to get more informqation about a library or its contents.\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `applewood_table` variable we used to store the result of the last code is actually an object called a data frame. A **_data frame_** (also written as DataFrame) is a data structure that holds two-dimensional data, like a table. Much of the data you see is in table format, which means a data frame is an excellent choice for a storage method. The parsers in pandas default to using data frames when they read data that appears to have multiple rows and columns.\n",
    "\n",
    "Each row in the data frame has an **_index_**. The index value uniquely identifies the row. You can think of it as a *primary key* field for the table. If the data already includes an index, we can tell pandas which column it is in. If there isn't an index already, pandas will create one. The index value is how we reference specific rows.\n",
    "\n",
    "The data frame has many built-in methods we can access to look at its contents. Here are some examples of some helpful ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many rows there are by printing the pandas-generated index values\n",
    "applewood_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the names of the columns\n",
    "applewood_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives you summary descriptive statistics on your data.\n",
    "applewood_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first five lines of the table.\n",
    "applewood_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the last five lines of data with\n",
    "applewood_table.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the read statement as needed. The example below uses the `read_table` parser, which defaults to the `TAB` character as a delimiter. We use the `sep` argument to tell pandas the file uses semicolon delimiters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slightly different example\n",
    "boston_table = pd.io.parsers.read_table(\"Boston_housing_SMALL.csv\", sep=\";\")\n",
    "print (boston_table)\n",
    "\n",
    "# Run this cell, then insert new cells to try some of the data frame methods like we did previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select specific fields when reading csv files if we don't need every column for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from just two columns of the source.\n",
    "applewood_subset = pd.io.parsers.read_csv(\"Applewood_2011.csv\", usecols=['Profit','Location'])\n",
    "applewood_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel files\n",
    "The `read_excel()` method in pandas can read Excel 2003 (.xls) and Excel 2007+ (.xlsx) files using the xlrd Python module. The `to_excel()` instance method is used for saving a DataFrame to Excel. Generally the semantics are similar to working with csv data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the most basic use-case, `read_excel` takes a path to an Excel file, and the sheet_name indicating which sheet to parse.\n",
    "\n",
    "```\n",
    "# Returns a DataFrame\n",
    "read_excel('path_to_file.xls', sheet_name='Sheet1')\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more of the available arguments:\n",
    "```\n",
    "Using the sheet name\n",
    "  read_excel('path_to_file.xls', 'Sheet1', index_col=None, na_values=['NA'])\n",
    "\n",
    "Using the sheet index:\n",
    "  read_excel('path_to_file.xls', 0, index_col=None, na_values=['NA'])\n",
    "\n",
    "Using all default values:\n",
    "  read_excel('path_to_file.xls')\n",
    "\n",
    "Using None to get all sheets:\n",
    "  read_excel('path_to_file.xls', sheet_name=None)\n",
    "\n",
    "Using a list to get multiple sheets:\n",
    "Returns the 1st and 4th sheet, as a dictionary of DataFrames.\n",
    "  read_excel('path_to_file.xls', sheet_name=['Sheet1', 3])\n",
    "```\n",
    "\n",
    "As you see in the last two entries, `read_excel` can read more than one sheet at a time by setting sheet_name to either a list of sheet names, a list of sheet positions, or None to read all sheets. Sheets can be specified by sheet index or sheet name, using an integer or string, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oyster_Weight_g</th>\n",
       "      <th>Oyster_Volume_CC</th>\n",
       "      <th>Pixels_3D</th>\n",
       "      <th>Pixels_2D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oyster_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.92</td>\n",
       "      <td>13.04</td>\n",
       "      <td>5136699</td>\n",
       "      <td>47907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.40</td>\n",
       "      <td>11.71</td>\n",
       "      <td>4795151</td>\n",
       "      <td>41458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.42</td>\n",
       "      <td>17.42</td>\n",
       "      <td>6453115</td>\n",
       "      <td>60891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.79</td>\n",
       "      <td>7.23</td>\n",
       "      <td>2895239</td>\n",
       "      <td>29949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.62</td>\n",
       "      <td>10.03</td>\n",
       "      <td>3672746</td>\n",
       "      <td>41616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Oyster_Weight_g  Oyster_Volume_CC  Pixels_3D  Pixels_2D\n",
       "Oyster_ID                                                         \n",
       "1                    12.92             13.04    5136699      47907\n",
       "2                    11.40             11.71    4795151      41458\n",
       "3                    17.42             17.42    6453115      60891\n",
       "4                     6.79              7.23    2895239      29949\n",
       "5                     9.62             10.03    3672746      41616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: read from an Excel file\n",
    "# The data already includes an index value so we can specify that pandas uses it in the data.\n",
    "import pandas as pd\n",
    "oyster_data = pd.read_excel(\"Oysters.xlsx\", \"Original\", index_col='Oyster_ID', na_values=['NA'])\n",
    "oyster_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database files\n",
    "pandas also has built-in capabilities for reading database files. Many of the best known databases rely on SQL and pandas leverages SQL for data access. The library `sqlalchemy` provides these functions for SQL databases like SQLite, MySQL, SQL Server, and MS Access (through the ODBC standard). We will not have time to cover these in class but you should be aware of them for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "A full discussion of missing data is beyond the scope of this class. However, here is a link to some of the basic functionality built into pandas for handling missing data.\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/10min.html#missing-data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a csv or Excel file\n",
    "It's pretty straightforward. Two code examples are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the Applewood data to a csv file\n",
    "applewood_table.to_csv('new_AW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write two columns from the oyster data to an Excel file with a named sheet\n",
    "oyster_data.to_excel('new_oyster.xlsx', sheet_name='Awesome',columns=['Oyster_Weight_g', 'Oyster_Volume_CC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming exercises\n",
    "Restart the kernel before you start on these. It will free up memory but you have to include the reading code for the Oysters.xlsx file in #2.\n",
    "1. Read data from the tab delimited file `fishcatch.dat`, display the first 5 rows, then write all of the data to an Excel file named \"finnish_fish.xlsx\" in your repository. To see how the data file is organized look at the \"fish_info.txt\" file. \n",
    "\n",
    "2. Read data from the 'Singers' sheet of the `Oysters.xlsx` file. Write only the singer names to a csv file named \"oyster_faves.csv\" in your repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index Oyster_ID invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-cca2030b5826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfish_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fishcatch.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfish_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Oysters.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Singers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Oyster_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfish_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfish_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Oysters.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Singers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Oyster_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   2271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2272\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexnamerow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_index\u001b[1;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1425\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_simple_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1426\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_get_simple_index\u001b[1;34m(self, data, columns)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m             \u001b[0mto_remove\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mix\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m   1450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Index %s invalid'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index Oyster_ID invalid"
     ]
    }
   ],
   "source": [
    "fish_table = pd.io.parsers.read_table(\"Fishcatch.txt\", header=None, sep=\",\")\n",
    "\n",
    "fish_data = pd.read_table('Oysters.xlsx', 'Singers', index_col='Oyster_ID', na_values=['NA'])\n",
    "fish_data.head()\n",
    "fish_data.to_excel('Oysters.xlsx', 'Singers', index_col='Oyster_ID', na_values=['NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
